Proposal for Survey in Selection and Synthesis of formulas and programs
----

Goals
----

The goal of this will be to summarize the main contributions of methods that contribute to symboling reasoning, formula/program synthesis and learning in all of these domains. The main two tasks to solve and have a summarize of state of the art is

1) Methods for selection of key concepts from a library of concepts/symbols
2) Methods for synthesis of programs/formulas/discrete structures
3) Optimization methods for discrete/symbolic optimization

Compression of ideas from papers
----

When reading each paper it will be important to identify

1) the problem they are solving (i.e. 1), 2) 3))
2) the main ideas of the methods
3) advantages and limitation of the methods
4) ways it connect to our current projects (Coq proof synthesis and Loop Invariant Learning)

Section: Papers for 1) Methods for selection of key concepts from a library of concepts/symbols
----

premise selection
- [ ] DeepMath - Deep Sequence Models for Premise Selection (https://arxiv.org/abs/1606.04442) 
- [ ] Premise Selection for Theorem Proving by Deep Graph Embedding (https://arxiv.org/abs/1709.09994)
- [ ] ATPboost: Learning Premise Selection in Binary Setting with ATP Feedback (https://arxiv.org/abs/1802.03375)
- [ ] Premise selection with neural networks and distributed representation of features (https://arxiv.org/abs/1807.10268)

memory networks
- [ ] Memory Networks gi(https://arxiv.org/abs/1410.3916)

- [ ] Machine Learning for Instance Selection (http://matryoshka.gforge.inria.fr/pubs/ml_instance_abstract.pdf, https://www.google.com/search?q=machine+learning+for+instance+selection+in+SMT+solving&rlz=1C5CHFA_enUS741US741&oq=machine+learning+for+instance+selection+in+SMT+solving&aqs=chrome..69i57.8798j0j4&sourceid=chrome&ie=UTF-8)


Section: Papers for 2) Methods for synthesis of programs/formulas/discrete structures
----

- [ ] Learning Loop Invariants for Program Verification (https://papers.nips.cc/paper/8001-learning-loop-invariants-for-program-verification.pdf, https://www.youtube.com/watch?v=Q1eAO2pZPZ8, https://www.facebook.com/nipsfoundation/videos/session-2-room-220-e/2106994059390210/)

- [ ] Execution-Guided Neural Program Synthesis (https://openreview.net/pdf?id=H1gfOiAqYm)
- [ ] Sorcar: Property-Driven Algorithms for Learning Small Conjunctive Invariants (talk to me for pdf)
- [ ] Learning Invariants Using Decision Trees and Implication Counterexamples (https://dl.acm.org/citation.cfm?doid=2837614.2837664)
- [ ] Abstract Learning Frameworks for Synthesis (https://link.springer.com/content/pdf/10.1007%2F978-3-662-49674-9_10.pdf)
- [ ] ICE: A Robust Framework for Learning Invariants (https://link.springer.com/content/pdf/10.1007%2F978-3-319-08867-9_5.pdf)

Section: Papers for 3) Optimization methods for discrete/symbolic optimization
----

TODO: papers on RL/DL composing Neural Networks

- [ ] Automatic Local Rewriting for Combinatorial Optimization (https://arxiv.org/abs/1810.00337)

Neural Module Networks:

- [ ] Neural Module Networks (https://arxiv.org/abs/1511.02799)
- [ ] Learning to Reason with Neural Module Networks (https://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/)

Discussion
----

Note this list is not complete so feel free to update or add papers that have been missed. Other potential good source for expanding this list could be 

- found in the AITP conference: http://aitp-conference.org/
- https://people.mpi-sws.org/~neider/

TODOs
----

- put hammers on sections/lists
- put (Coq) Hammers on sections/lists

Other useful ideas for projects
----

Section 4) Non-stationary policies
----

TODO ask Nan and Dimitrios
- [ ] AlphaStar (https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/)


Section 5) Curriculum learning
----

TODO

Section 6) Sparse-rewards
----

TODO
